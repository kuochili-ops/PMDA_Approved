
import streamlit as st
import pandas as pd
import requests
import io
import re
import time

# è®€å– Streamlit Cloud Secrets Manager çš„é‡‘é‘°
AZURE_KEY = st.secrets["AZURE_KEY"]
AZURE_REGION = st.secrets["AZURE_REGION"]

# Microsoft Translator API è¨­å®š
endpoint = "https://api.cognitive.microsofttranslator.com/translate"
headers = {
    "Ocp-Apim-Subscription-Key": AZURE_KEY,
    "Ocp-Apim-Subscription-Region": AZURE_REGION,
    "Content-type": "application/json"
}

def kegg_drug_english_names(jp_name):
    """æŸ¥è©¢ KEGG APIï¼Œå›å‚³å•†å“åèˆ‡å­¸åï¼ˆè‹±æ–‡ï¼‰ï¼ŒæŸ¥ä¸åˆ°å‰‡å›å‚³ç©ºå­—ä¸²"""
    url = f"https://rest.kegg.jp/find/drug/{jp_name}"
    try:
        resp = requests.get(url, timeout=10)
        if resp.ok and resp.text:
            line = resp.text.split('\n')[0]
            fields = line.split()
            if len(fields) > 1:
                names = [n.strip() for n in fields[1].split(';')]
                # å•†å“åï¼ˆè‹±æ–‡ï¼‰ï¼šé€šå¸¸æ˜¯é¦–å­—å¤§å¯«ä¸”æœ‰éå…¨å¤§å¯«
                trade_names = [n for n in names if n and n[0].isupper() and not n.isupper()]
                # å­¸åï¼ˆè‹±æ–‡ï¼‰ï¼šå…¨è‹±æ–‡ä¸”é¦–å­—æ¯å¤§å¯«
                english_names = [n for n in names if n and n[0].isupper() and n.isalpha()]
                return {
                    "trade_name_en_kegg": trade_names[0] if trade_names else "",
                    "ingredient_en_kegg": english_names[0] if english_names else ""
                }
    except Exception:
        pass
    return {"trade_name_en_kegg": "", "ingredient_en_kegg": ""}

def ms_translator(text, from_lang="ja"):
    """Microsoft Translator API å–®å¥ç¿»è­¯æˆè‹±æ–‡"""
    body = [{"text": text}]
    params = {"api-version": "3.0", "from": from_lang, "to": ["en"]}
    try:
        resp = requests.post(endpoint, params=params, headers=headers, json=body, timeout=10)
        if resp.ok:
            data = resp.json()
            return data[0]["translations"][0]["text"]
    except Exception:
        pass
    return ""

def ms_translator_multi(japanese_data_list):
    """Microsoft Translator API æ‰¹æ¬¡ç¿»è­¯å•†å“åã€åŠŸæ•ˆç­‰ï¼ˆç¹ä¸­ã€è‹±æ–‡ï¼‰"""
    results = []
    for item in japanese_data_list:
        body = [{"text": f"{item['trade_name_jp']} {item['ingredient_jp']} {item['efficacy_jp']}"}]
        params = {"api-version": "3.0", "from": "ja", "to": ["zh-Hant", "en"]}
        resp = requests.post(endpoint, params=params, headers=headers, json=body)
        data = resp.json()[0]["translations"]
        results.append({
            "trade_name_zh": data[0]["text"],
            "trade_name_en_translator": data[1]["text"],
            "efficacy_zh": data[0]["text"],
            "efficacy_en": data[1]["text"]
        })
    return results

def process_uploaded_file(uploaded_file):
    try:
        filename = uploaded_file.name
        file_type = uploaded_file.type
        filename_lower = filename.lower()
        if 'excel' in file_type or filename_lower.endswith(('.xlsx', '.xls')):
            df = pd.read_excel(uploaded_file, sheet_name=0, skiprows=2)
        elif 'csv' in file_type or filename_lower.endswith('.csv'):
            csv_data = io.StringIO(uploaded_file.getvalue().decode("utf-8"))
            df = pd.read_csv(csv_data, skiprows=2)
        else:
            st.error("ä¸æ”¯æ´çš„æª”æ¡ˆæ ¼å¼ã€‚")
            return None
        df.columns = df.columns.str.replace(r'[\s\n\u3000]', '', regex=True)
        rename_map = {}
        for col in df.columns:
            if re.match(r'^è²©.*å£².*å.*', col):
                rename_map[col] = 'Trade_Name_JP'
            elif re.match(r'^æˆ.*åˆ†.*å.*', col):
                rename_map[col] = 'Ingredient_JP'
            elif re.match(r'^åŠ¹èƒ½.*åŠ¹æœ.*', col):
                rename_map[col] = 'Efficacy_JP'
            elif col == 'æ‰¿èªæ—¥':
                rename_map[col] = 'Approval_Date'
            elif col == 'åˆ†é‡':
                rename_map[col] = 'Category'
            elif col.startswith('No'):
                rename_map[col] = 'No'
            elif col.startswith('æ‰¿èª'):
                rename_map[col] = 'Approval_Type'
        df = df.rename(columns=rename_map)
        key_cols = ['Category', 'Approval_Date', 'No', 'Trade_Name_JP', 'Approval_Type', 'Ingredient_JP', 'Efficacy_JP']
        df = df[key_cols].dropna(subset=['Trade_Name_JP', 'Ingredient_JP', 'Efficacy_JP'], how='all').reset_index(drop=True)
        return df
    except Exception as e:
        st.error(f"è™•ç†æª”æ¡ˆ {uploaded_file.name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None

def translate_and_combine(df):
    st.info("æ­£åœ¨æŸ¥è©¢ä¸»æˆåˆ†èˆ‡å•†å“åè‹±æ–‡ï¼ˆKEGGâ†’Microsoft Translatorï¼‰...")
    trade_name_en_list = []
    ingredient_en_list = []
    for idx, row in df.iterrows():
        # å…ˆæŸ¥ KEGG
        kegg_result = kegg_drug_english_names(row['Trade_Name_JP'])
        trade_name_en = kegg_result["trade_name_en_kegg"]
        ingredient_en = kegg_result["ingredient_en_kegg"]
        # è‹¥æŸ¥ä¸åˆ°å†ç”¨ Microsoft Translator
        if not trade_name_en:
            trade_name_en = ms_translator(row['Trade_Name_JP'])
        if not ingredient_en:
            ingredient_en = ms_translator(row['Ingredient_JP'])
        trade_name_en_list.append(trade_name_en)
        ingredient_en_list.append(ingredient_en)
        time.sleep(0.34)  # KEGG é »ç‡é™åˆ¶

    # å…¶ä»–æ¬„ä½ç¿»è­¯
    data_for_translation = df.apply(
        lambda row: {
            'trade_name_jp': row['Trade_Name_JP'],
            'ingredient_jp': row['Ingredient_JP'],
            'efficacy_jp': row['Efficacy_JP']
        },
        axis=1
    ).tolist()
    st.info(f"æ­£åœ¨ç¿»è­¯ {len(data_for_translation)} ç­†è—¥å“è³‡æ–™ï¼ˆå•†å“åã€åŠŸæ•ˆï¼‰...")
    translated_results = ms_translator_multi(data_for_translation)
    df_translated = pd.DataFrame(translated_results)

    # åˆä½µçµæœ
    final_df = pd.concat([df.reset_index(drop=True), df_translated.reset_index(drop=True)], axis=1)
    final_df['Trade Name/Company (English)'] = trade_name_en_list
    final_df['Ingredient Name (English)'] = ingredient_en_list

    # æ¬„ä½é¡¯ç¤ºåç¨±
    display_names = {
        'Category': 'åˆ†é‡ (Category)',
        'Approval_Date': 'æ‰¿èªæ—¥',
        'No': 'No.',
        'Trade_Name_JP': 'è²©è³£å/å…¬å¸ (æ—¥æ–‡)',
        'Trade Name/Company (English)': 'Trade Name/Company (English)',
        'Ingredient_JP': 'æˆåˆ†å (æ—¥æ–‡)',
        'Ingredient Name (English)': 'Ingredient Name (English)',
        'Approval_Type': 'æ‰¿èªé¡å‹',
        'Efficacy_JP': 'åŠŸæ•ˆãƒ»æ•ˆæœ (æ—¥æ–‡)',
        'efficacy_zh': 'åŠŸæ•ˆãƒ»æ•ˆæœ (ä¸­æ–‡)',
        'efficacy_en': 'Efficacy/Effects (English)'
    }
    final_df = final_df.rename(columns=display_names)
    # åªä¿ç•™éœ€è¦çš„æ¬„ä½
    keep_cols = [
        'åˆ†é‡ (Category)', 'æ‰¿èªæ—¥', 'No.', 'è²©è³£å/å…¬å¸ (æ—¥æ–‡)', 'Trade Name/Company (English)',
        'æˆåˆ†å (æ—¥æ–‡)', 'Ingredient Name (English)', 'æ‰¿èªé¡å‹',
        'åŠŸæ•ˆãƒ»æ•ˆæœ (æ—¥æ–‡)', 'åŠŸæ•ˆãƒ»æ•ˆæœ (ä¸­æ–‡)', 'Efficacy/Effects (English)'
    ]
    final_df = final_df[[col for col in keep_cols if col in final_df.columns]]
    return final_df

def main():
    st.set_page_config(layout="wide", page_title="PMDA æ—¥æœ¬æ–°è—¥ç¿»è­¯åˆ—è¡¨ç”Ÿæˆå™¨")
    st.title("ğŸ‡¯ğŸ‡µ PMDA æ—¥æœ¬æ–°è—¥ç¿»è­¯åˆ—è¡¨ç”Ÿæˆå™¨ (KEGG+Microsoft Translator ç‰ˆ)")
    uploaded_files = st.file_uploader(
        "ä¸Šå‚³æ–°è—¥åˆ—è¡¨æª”æ¡ˆ (CSV/XLSX)",
        type=['csv', 'xlsx', 'xls'],
        accept_multiple_files=True
    )
    if uploaded_files:
        for uploaded_file in uploaded_files:
            df = process_uploaded_file(uploaded_file)
            if df is not None:
                translated_df = translate_and_combine(df)
                if translated_df is not None:
                    st.subheader(f"ç¿»è­¯çµæœï¼š{uploaded_file.name}")
                    # åˆ†æ®µä¾æœˆä»½é¡¯ç¤º
                    translated_df["æœˆä»½"] = pd.to_datetime(translated_df["æ‰¿èªæ—¥"], errors="coerce").dt.month.astype(str) + "æœˆ"
                    month_groups = translated_df.groupby("æœˆä»½")
                    tabs = st.tabs([f"{month}" for month in month_groups.groups.keys()])
                    for i, (month, group_df) in enumerate(month_groups):
                        with tabs[i]:
                            st.header(f"{month} ç¿»è­¯çµæœ")
                            st.dataframe(group_df, use_container_width=True, hide_index=True)
                            # ä¸‹è¼‰æŒ‰éˆ•
                            csv_export = group_df.to_csv(index=False).encode('utf-8')
                            st.download_button(
                                label=f"ğŸ“¥ ä¸‹è¼‰ {month} ç¿»è­¯çµæœ (CSV)",
                                data=csv_export,
                                file_name=f"{uploaded_file.name}_{month}_Translated.csv",
                                mime='text/csv'
                            )

if __name__ == "__main__":
