
import streamlit as st
import pandas as pd
import requests
import re
import time
import os

# ====== API é‡‘é‘°è¨­å®šï¼ˆè«‹å¡«å…¥ä½ è‡ªå·±çš„ï¼‰ ======
AZURE_KEY = st.secrets["AZURE_KEY"]
AZURE_REGION = st.secrets["AZURE_REGION"]
endpoint = "https://api.cognitive.microsofttranslator.com/translate"
headers = {
    "Ocp-Apim-Subscription-Key": AZURE_KEY,
    "Ocp-Apim-Subscription-Region": AZURE_REGION,
    "Content-type": "application/json"
}

# ====== KEGG API æŸ¥è©¢å‡½å¼ ======
def kegg_drug_english_names(jp_name):
    url = f"https://rest.kegg.jp/find/drug/{jp_name}"
    try:
        resp = requests.get(url, timeout=10)
        if resp.ok and resp.text:
            line = resp.text.split('\n')[0]
            fields = line.split()
            if len(fields) > 1:
                names = [n.strip() for n in fields[1].split(';')]
                trade_names = [n for n in names if n and n[0].isupper() and not n.isupper()]
                english_names = [n for n in names if n and n[0].isupper() and n.isalpha()]
                return {
                    "trade_name_en_kegg": trade_names[0] if trade_names else "",
                    "ingredient_en_kegg": english_names[0] if english_names else ""
                }
    except Exception:
        pass
    return {"trade_name_en_kegg": "", "ingredient_en_kegg": ""}

# ====== Microsoft Translator API å–®å¥ç¿»è­¯ ======
def ms_translator(text, from_lang="ja"):
    body = [{"text": text}]
    params = {"api-version": "3.0", "from": from_lang, "to": ["en"]}
    try:
        resp = requests.post(endpoint, params=params, headers=headers, json=body, timeout=10)
        if resp.ok:
            data = resp.json()
            return data[0]["translations"][0]["text"]
    except Exception:
        pass
    return ""

# ====== è³‡æ–™æ¸…ç†å‡½å¼ ======
def clean_dataframe(df):
    # æ¬„ä½æ¨™æº–åŒ–
    rename_map = {}
    for col in df.columns:
        if re.match(r'^è²©.*å£².*å.*', col):
            rename_map[col] = 'è²©è³£å/å…¬å¸ (æ—¥æ–‡)'
        elif re.match(r'^æˆ.*åˆ†.*å.*', col):
            rename_map[col] = 'æˆåˆ†å (æ—¥æ–‡)'
    df = df.rename(columns=rename_map)
    # åªä¿ç•™æœ‰æˆåˆ†åçš„è¡Œ
    if 'æˆåˆ†å (æ—¥æ–‡)' in df.columns:
        df = df.dropna(subset=['æˆåˆ†å (æ—¥æ–‡)'], how='any')
    # åªå–è—¥åï¼ˆå»é™¤å…¬å¸åç­‰å¤šé¤˜å…§å®¹ï¼‰
    if 'è²©è³£å/å…¬å¸ (æ—¥æ–‡)' in df.columns:
        df['è²©è³£å/å…¬å¸ (æ—¥æ–‡)'] = df['è²©è³£å/å…¬å¸ (æ—¥æ–‡)'].astype(str).str.split('\n').str[0]
    # å»é™¤å…¨ç©ºç™½è¡Œ
    df = df.dropna(how='all')
    # å»é™¤å…¨ç‚ºç©ºå­—ä¸²çš„è¡Œ
    df = df[~(df.applymap(lambda x: str(x).strip() == '').all(axis=1))]
    df = df.reset_index(drop=True)
    return df

# ====== ç¿»è­¯ä¸»æµç¨‹ï¼Œå«é€²åº¦é¡¯ç¤º ======
def translate_and_combine(df):
    df = clean_dataframe(df)
    st.write(f"æœ¬æœˆä»½å…± {len(df)} ç­†")
    trade_name_en_list = []
    ingredient_en_list = []
    progress = st.empty()
    for idx, row in df.iterrows():
        progress.info(f"ç¬¬ {idx+1} é …ç¿»è­¯ä¸­â€¦")
        kegg_result = kegg_drug_english_names(str(row.get('è²©è³£å/å…¬å¸ (æ—¥æ–‡)', '')))
        trade_name_en = kegg_result["trade_name_en_kegg"]
        ingredient_en = kegg_result["ingredient_en_kegg"]
        if not trade_name_en:
            trade_name_en = ms_translator(str(row.get('è²©è³£å/å…¬å¸ (æ—¥æ–‡)', '')))
        if not ingredient_en:
            ingredient_en = ms_translator(str(row.get('æˆåˆ†å (æ—¥æ–‡)', '')))
        trade_name_en_list.append(trade_name_en)
        ingredient_en_list.append(ingredient_en)
        time.sleep(0.34)  # KEGG é »ç‡é™åˆ¶
    progress.success("å…¨éƒ¨ç¿»è­¯å®Œæˆï¼")
    df['Trade Name/Company (English)'] = trade_name_en_list
    df['Ingredient Name (English)'] = ingredient_en_list
    return df

# ====== åˆ†é å¦å­˜ CSV ======
def save_sheets_to_csv(uploaded_file):
    xls = pd.ExcelFile(uploaded_file)
    sheet_map = {}
    for sheet_name in xls.sheet_names:
        df = pd.read_excel(xls, sheet_name)
        # å˜—è©¦æ‰¾æœˆä»½
        month_match = re.search(r'(\d+)æœˆ', sheet_name)
        if not month_match:
            for col in df.columns:
                m = re.search(r'(\d+)æœˆ', str(col))
                if m:
                    month_match = m
                    break
        if month_match:
            month = month_match.group(1) + "æœˆ"
        else:
            month = sheet_name
        csv_name = f"{month}.csv"
        df.to_csv(csv_name, index=False, encoding="utf-8")
        sheet_map[month] = csv_name
    return sheet_map

# ====== Streamlit ä¸»ç¨‹å¼ ======
def main():
    st.set_page_config(layout="wide", page_title="PMDA æ—¥æœ¬æ–°è—¥ç¿»è­¯åˆ—è¡¨ç”Ÿæˆå™¨")
    st.title("ğŸ‡¯ğŸ‡µ PMDA æ—¥æœ¬æ–°è—¥ç¿»è­¯åˆ—è¡¨ç”Ÿæˆå™¨ (è‡ªå‹•åˆ†é è½‰ CSV + ç¿»è­¯)")
    uploaded_file = st.file_uploader("ä¸Šå‚³ PMDA å…¬å‘Š Excel æª”æ¡ˆ", type=['xlsx', 'xls'])
    if uploaded_file:
        st.info("æ­£åœ¨è‡ªå‹•åˆ†å‰²å„æœˆä»½...")
        month_csv_map = save_sheets_to_csv(uploaded_file)
        if not month_csv_map:
            st.warning("æœªåµæ¸¬åˆ°ä»»ä½•æœˆä»½åˆ†é ã€‚")
            return
        for month, csv_name in month_csv_map.items():
            st.subheader(f"{month} ç¿»è­¯çµæœ")
            df = pd.read_csv(csv_name, encoding="utf-8")
            translated_df = translate_and_combine(df)
            st.dataframe(translated_df, use_container_width=True, hide_index=True)
            csv_export = translated_df.to_csv(index=False).encode('utf-8')
            st.download_button(
                label=f"ğŸ“¥ ä¸‹è¼‰ {month} ç¿»è­¯çµæœ (CSV)",
                data=csv_export,
                file_name=f"{month}_Translated.csv",
                mime='text/csv'
            )
            os.remove(csv_name)


if __name__ == "__main__":
    main()
