
import streamlit as st
import pandas as pd
import requests
import re
import time
import os

# ====== API é‡‘é‘°è¨­å®š ======
AZURE_KEY = st.secrets["AZURE_KEY"]
AZURE_REGION = st.secrets["AZURE_REGION"]
endpoint = "https://api.cognitive.microsofttranslator.com/translate"
headers = {
    "Ocp-Apim-Subscription-Key": AZURE_KEY,
    "Ocp-Apim-Subscription-Region": AZURE_REGION,
    "Content-type": "application/json"
}

# ====== KEGG API æŸ¥è©¢å‡½å¼ ======
def kegg_drug_english_names(jp_name):
    url = f"https://rest.kegg.jp/find/drug/{jp_name}"
    try:
        resp = requests.get(url, timeout=10)
        if resp.ok and resp.text:
            line = resp.text.split('\n')[0]
            fields = line.split()
            if len(fields) > 1:
                names = [n.strip() for n in fields[1].split(';')]
                trade_names = [n for n in names if n and n[0].isupper() and not n.isupper()]
                english_names = [n for n in names if n and n[0].isupper() and n.isalpha()]
                return {
                    "trade_name_en_kegg": trade_names[0] if trade_names else "",
                    "ingredient_en_kegg": english_names[0] if english_names else ""
                }
    except Exception:
        pass
    return {"trade_name_en_kegg": "", "ingredient_en_kegg": ""}

# ====== Microsoft Translator API å–®å¥ç¿»è­¯ ======
def ms_translator(text, from_lang="ja"):
    body = [{"text": text}]
    params = {"api-version": "3.0", "from": from_lang, "to": ["en"]}
    try:
        resp = requests.post(endpoint, params=params, headers=headers, json=body, timeout=10)
        if resp.ok:
            data = resp.json()
            return data[0]["translations"][0]["text"]
    except Exception:
        pass
    return ""

# ====== è³‡æ–™æ¸…ç†å‡½å¼ï¼ˆå¼·åŒ–ç‰ˆï¼‰ ======
def clean_dataframe(df):
    if not isinstance(df, pd.DataFrame):
        return pd.DataFrame()
    rename_map = {}
    for col in df.columns:
        if re.match(r'^è²©.*å£².*å.*', str(col)):
            rename_map[col] = 'è²©è³£å/å…¬å¸ (æ—¥æ–‡)'
        elif re.match(r'^æˆ.*åˆ†.*å.*', str(col)):
            rename_map[col] = 'æˆåˆ†å (æ—¥æ–‡)'
        elif re.match(r'^No\\.?$', str(col)):
            rename_map[col] = 'No.'
    df = df.rename(columns=rename_map)
    # åªä¿ç•™æœ‰è—¥å“ç·¨è™Ÿã€è²©è³£åã€æˆåˆ†åçš„è¡Œ
    if {'No.', 'è²©è³£å/å…¬å¸ (æ—¥æ–‡)', 'æˆåˆ†å (æ—¥æ–‡)'}.issubset(df.columns):
        df = df[
            df['No.'].apply(lambda x: str(x).strip().isdigit()) &
            df['è²©è³£å/å…¬å¸ (æ—¥æ–‡)'].astype(str).str.strip().ne('') &
            df['æˆåˆ†å (æ—¥æ–‡)'].astype(str).str.strip().ne('')
        ]
    elif 'æˆåˆ†å (æ—¥æ–‡)' in df.columns:
        df = df[df['æˆåˆ†å (æ—¥æ–‡)'].notnull() & (df['æˆåˆ†å (æ—¥æ–‡)'].astype(str).str.strip() != '')]
    else:
        df = pd.DataFrame()  # æ²’æœ‰ä¸»è¦æ¬„ä½å°±å›å‚³ç©ºè¡¨
    # å»é™¤å…¨ç©ºç™½è¡Œ
    if not df.empty:
        df = df.dropna(how='all')
        df = df[~(df.applymap(lambda x: str(x).strip() == '').all(axis=1))]
        df = df.reset_index(drop=True)
    return df

# ====== åˆ†é å¦å­˜ CSVï¼ˆpandas è®€å–ç¬¬3åˆ—ç‚ºæ¬„ä½åï¼‰ ======
def save_sheets_to_csv_by_header3(uploaded_file):
    xls = pd.ExcelFile(uploaded_file)
    sheet_map = {}
    for sheet_name in xls.sheet_names:
        try:
            raw_df = pd.read_excel(xls, sheet_name=sheet_name, header=2)  # ç¬¬3åˆ—ç‚ºæ¬„ä½å
        except Exception as e:
            st.write(f"åˆ†é ã€Œ{sheet_name}ã€è®€å–å¤±æ•—ï¼š{e}")
            continue
        if raw_df is None or raw_df.empty:
            st.write(f"åˆ†é ã€Œ{sheet_name}ã€ç„¡åŸå§‹è³‡æ–™ï¼Œå·²è·³éã€‚")
            continue
        raw_count = len(raw_df)
        df = clean_dataframe(raw_df)
        clean_count = len(df)
        if df is None or df.empty:
            st.write(f"åˆ†é ã€Œ{sheet_name}ã€ç„¡æœ‰æ•ˆè³‡æ–™ï¼Œå·²è·³éã€‚")
            continue
        # å˜—è©¦æ‰¾æœˆä»½
        month_match = re.search(r'(\d+)æœˆ', sheet_name)
        if not month_match:
            for col in df.columns:
                m = re.search(r'(\d+)æœˆ', str(col))
                if m:
                    month_match = m
                    break
        if month_match:
            month = month_match.group(1) + "æœˆ"
        else:
            month = sheet_name
        csv_name = f"{month}.csv"
        df.to_csv(csv_name, index=False, encoding="utf-8")
        sheet_map[month] = (csv_name, raw_count, clean_count)
    return sheet_map

# ====== ç¿»è­¯ä¸»æµç¨‹ ======
def translate_and_combine(df):
    st.write(f"æ¸…ç†å¾Œæœ‰æ•ˆè³‡æ–™å…± {len(df)} ç­†")
    trade_name_en_list = []
    ingredient_en_list = []
    progress = st.empty()
    for idx, row in df.iterrows():
        progress.info(f"ç¬¬ {idx+1} é …ç¿»è­¯ä¸­â€¦")
        kegg_result = kegg_drug_english_names(str(row.get('è²©è³£å/å…¬å¸ (æ—¥æ–‡)', '')))
        trade_name_en = kegg_result["trade_name_en_kegg"]
        ingredient_en = kegg_result["ingredient_en_kegg"]
        if not trade_name_en:
            trade_name_en = ms_translator(str(row.get('è²©è³£å/å…¬å¸ (æ—¥æ–‡)', '')))
        if not ingredient_en:
            ingredient_en = ms_translator(str(row.get('æˆåˆ†å (æ—¥æ–‡)', '')))
        trade_name_en_list.append(trade_name_en)
        ingredient_en_list.append(ingredient_en)
        time.sleep(0.34)  # KEGG é »ç‡é™åˆ¶
    progress.success("å…¨éƒ¨ç¿»è­¯å®Œæˆï¼")
    df['Trade Name/Company (English)'] = trade_name_en_list
    df['Ingredient Name (English)'] = ingredient_en_list
    return df

# ====== Streamlit ä¸»ç¨‹å¼ ======
def main():
    st.set_page_config(layout="wide", page_title="PMDA æ—¥æœ¬æ–°è—¥ç¿»è­¯åˆ—è¡¨ç”Ÿæˆå™¨")
    st.title("ğŸ‡¯ğŸ‡µ PMDA æ—¥æœ¬æ–°è—¥ç¿»è­¯åˆ—è¡¨ç”Ÿæˆå™¨ (è‡ªå‹•åˆ†é è½‰ CSV + ç¿»è­¯)")
    uploaded_file = st.file_uploader("ä¸Šå‚³ PMDA å…¬å‘Š Excel æª”æ¡ˆ", type=['xlsx', 'xls'])
    if uploaded_file:
        st.info("æ­£åœ¨è‡ªå‹•åˆ†å‰²å„æœˆä»½ï¼ˆä»¥ç¬¬3åˆ—ç‚ºæ¬„ä½åï¼‰...")
        month_csv_map = save_sheets_to_csv_by_header3(uploaded_file)
        if not month_csv_map:
            st.warning("æœªåµæ¸¬åˆ°ä»»ä½•æœ‰æ•ˆåˆ†é ã€‚")
            return
        for month, (csv_name, raw_count, clean_count) in month_csv_map.items():
            st.subheader(f"{month} ç¿»è­¯çµæœ")
            st.write(f"åŸå§‹ç­†æ•¸ï¼š{raw_count}ï¼Œæ¸…ç†å¾Œï¼š{clean_count}")
            df = pd.read_csv(csv_name, encoding="utf-8")
            if df.empty:
                st.warning(f"{month} ç„¡æœ‰æ•ˆè³‡æ–™ï¼Œå·²è·³éã€‚")
                continue
            translated_df = translate_and_combine(df)
            st.dataframe(translated_df, use_container_width=True, hide_index=True)
            csv_export = translated_df.to_csv(index=False).encode('utf-8')
            st.download_button(
                label=f"ğŸ“¥ ä¸‹è¼‰ {month} ç¿»è­¯çµæœ (CSV)",
                data=csv_export,
                file_name=f"{month}_Translated.csv",
                mime='text/csv'
            )
            os.remove(csv_name)

if __name__ == "__main__":
    main()
