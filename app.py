import streamlit as st
import pandas as pd
import json
import time
import requests
import io
import re

# --- é…ç½® ---
MODEL_NAME = "gemini-1.5-flash"  # æ”¹æˆç©©å®šå¯ç”¨çš„æ¨¡å‹
API_URL = f"https://generativelanguage.googleapis.com/v1beta/models/{MODEL_NAME}:generateContent"
def translate_drug_info(japanese_data_list):
    """ä½¿ç”¨ Gemini API ç¿»è­¯è—¥å“è³‡è¨Šåˆ—è¡¨ï¼Œä¸¦è¦æ±‚çµæ§‹åŒ– JSON è¼¸å‡ºã€‚"""
    if not japanese_data_list:
        return []

    system_prompt = (
        "You are an expert pharmaceutical translator. Translate the provided Japanese drug information "
        "into Traditional Chinese and English. You MUST return a single JSON array that matches the provided JSON schema. "
        "Maintain the original Japanese text if the Japanese column contains complex formatting or identifiers. "
        "The translation must be accurate and concise."
    )

    data_to_translate = "\n---\n".join([
        f"Trade Name (JP): {item['trade_name_jp']}\nIngredient (JP): {item['ingredient_jp']}\nEfficacy (JP): {item['efficacy_jp']}"
        for item in japanese_data_list
    ])

    user_query = f"Translate the following Japanese drug entries. Respond ONLY with the JSON array.\n\n{data_to_translate}"

    response_schema = {
        "type": "ARRAY",
        "items": {
            "type": "OBJECT",
            "properties": {
                "trade_name_zh": {"type": "STRING"},
                "trade_name_en": {"type": "STRING"},
                "ingredient_zh": {"type": "STRING"},
                "ingredient_en": {"type": "STRING"},
                "efficacy_zh": {"type": "STRING"},
                "efficacy_en": {"type": "STRING"}
            },
            "required": ["trade_name_zh", "trade_name_en", "ingredient_zh", "ingredient_en", "efficacy_zh", "efficacy_en"]
        }
    }

    payload = {
        "contents": [{"parts": [{"text": user_query}]}],
        "systemInstruction": {"parts": [{"text": system_prompt}]},
        "generationConfig": {
            "responseMimeType": "application/json",
            "responseSchema": response_schema
        }
    }

    response = None
    max_retries = 5
    for attempt in range(max_retries):
        try:
            response = requests.post(
                API_URL,
                headers={'Content-Type': 'application/json'},
                data=json.dumps(payload),
                timeout=60
            )
            response.raise_for_status()
            result = response.json()
            json_text = result.get('candidates', [{}])[0].get('content', {}).get('parts', [{}])[0].get('text')
            if json_text:
                return json.loads(json_text)
            st.error("API å›æ‡‰æˆåŠŸï¼Œä½†æœªæ‰¾åˆ°é æœŸçš„ JSON ç¿»è­¯çµæœã€‚")
            return None
        except requests.exceptions.RequestException as e:
            if response is not None and response.status_code == 403:
                st.error("API å‘¼å«å¤±æ•—ï¼š403 Forbiddenã€‚è«‹ç¢ºèªæ¨¡å‹æˆæ¬Šã€‚")
                return None
            if attempt < max_retries - 1:
                time.sleep(2 ** attempt)
            else:
                st.error(f"API å‘¼å«å¤±æ•—: {e}")
                return None
        except json.JSONDecodeError:
            st.error("ç¿»è­¯çµæœæ ¼å¼éŒ¯èª¤ï¼Œç„¡æ³•è§£æ JSONã€‚")
            return None
        except Exception as e:
            st.error(f"ç¿»è­¯éç¨‹ä¸­ç™¼ç”Ÿæ„å¤–éŒ¯èª¤: {e}")
            return None
    return None
def process_uploaded_file(uploaded_file):
    """è®€å– CSV/XLSX æª”æ¡ˆï¼Œæ¸…ç†è³‡æ–™ã€‚"""
    try:
        filename = uploaded_file.name
        file_type = uploaded_file.type
        filename_lower = filename.lower()

        if 'excel' in file_type or filename_lower.endswith(('.xlsx', '.xls')):
            df = pd.read_excel(uploaded_file, sheet_name=0, skiprows=2)
        elif 'csv' in file_type or filename_lower.endswith('.csv'):
            csv_data = io.StringIO(uploaded_file.getvalue().decode("utf-8"))
            df = pd.read_csv(csv_data, skiprows=2)
        else:
            st.error("ä¸æ”¯æ´çš„æª”æ¡ˆæ ¼å¼ã€‚")
            return None

        # æ¸…ç†æ¬„ä½åç¨±
        df.columns = df.columns.str.replace(r'[\s\nã€€]', '', regex=True)

        # æ­£å‰‡åŒ–æ¬„ä½å°æ‡‰
        rename_map = {}
        for col in df.columns:
            if re.match(r'^è²©.*å£².*å.*', col):
                rename_map[col] = 'Trade_Name_JP'
            elif re.match(r'^æˆ.*åˆ†.*å.*', col):
                rename_map[col] = 'Ingredient_JP'
            elif re.match(r'^åŠ¹èƒ½.*åŠ¹æœ.*', col):
                rename_map[col] = 'Efficacy_JP'
            elif col == 'æ‰¿èªæ—¥':
                rename_map[col] = 'Approval_Date'
            elif col == 'åˆ†é‡':
                rename_map[col] = 'Category'
            elif col.startswith('No'):
                rename_map[col] = 'No'
            elif col.startswith('æ‰¿èª'):
                rename_map[col] = 'Approval_Type'

        df = df.rename(columns=rename_map)

        # ç¯©é¸é—œéµæ¬„ä½
        key_cols = ['Category', 'Approval_Date', 'No', 'Trade_Name_JP', 'Approval_Type', 'Ingredient_JP', 'Efficacy_JP']
        df = df[key_cols].dropna(subset=['Trade_Name_JP', 'Ingredient_JP', 'Efficacy_JP'], how='all').reset_index(drop=True)

        return df
    except Exception as e:
        st.error(f"è™•ç†æª”æ¡ˆ {uploaded_file.name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None
def translate_and_combine(df):
    """ç¿»è­¯ä¸¦åˆä½µçµæœã€‚"""
    data_for_translation = df.apply(
        lambda row: {
            'trade_name_jp': row['Trade_Name_JP'],
            'ingredient_jp': row['Ingredient_JP'],
            'efficacy_jp': row['Efficacy_JP']
        },
        axis=1
    ).tolist()

    st.info(f"æ­£åœ¨ç¿»è­¯ {len(data_for_translation)} ç­†è—¥å“è³‡æ–™...")
    translated_results = translate_drug_info(data_for_translation)

    if translated_results is None or len(translated_results) != len(df):
        st.warning("æ‰¹æ¬¡ç¿»è­¯æ•¸é‡ä¸ä¸€è‡´ï¼Œæ”¹ç”¨é€ç­†ç¿»è­¯ã€‚")
        translated_results = []
        for item in data_for_translation:
            res = translate_drug_info([item])
            if res:
                translated_results.append(res[0])

    df_translated = pd.DataFrame(translated_results)
    final_df = pd.concat([df.reset_index(drop=True), df_translated.reset_index(drop=True)], axis=1)

    display_names = {
        'Category': 'åˆ†é‡ (Category)',
        'Approval_Date': 'æ‰¿èªæ—¥',
        'No': 'No.',
        'Trade_Name_JP': 'è²©è³£å/å…¬å¸ (æ—¥æ–‡)',
        'trade_name_zh': 'å•†å“åç¨±/å…¬å¸ (ä¸­æ–‡)',
        'trade_name_en': 'Trade Name/Company (English)',
        'Ingredient_JP': 'æˆåˆ†å (æ—¥æ–‡)',
        'ingredient_zh': 'æˆåˆ†åç¨± (ä¸­æ–‡)',
        'ingredient_en': 'Ingredient Name (English)',
        'Approval_Type': 'æ‰¿èªé¡å‹',
        'Efficacy_JP': 'åŠŸæ•ˆãƒ»æ•ˆæœ (æ—¥æ–‡)',
        'efficacy_zh': 'åŠŸæ•ˆãƒ»æ•ˆæœ (ä¸­æ–‡)',
        'efficacy_en': 'Efficacy/Effects (English)'
    }
    final_df = final_df.rename(columns=display_names)
    return final_df
def main():
    st.set_page_config(layout="wide", page_title="PMDA æ—¥æœ¬æ–°è—¥ç¿»è­¯åˆ—è¡¨ç”Ÿæˆå™¨")
    st.title("ğŸ‡¯ğŸ‡µ PMDA æ—¥æœ¬æ–°è—¥ç¿»è­¯åˆ—è¡¨ç”Ÿæˆå™¨")

    uploaded_files = st.file_uploader(
        "ä¸Šå‚³æ–°è—¥åˆ—è¡¨æª”æ¡ˆ (CSV/XLSX)", 
        type=['csv', 'xlsx', 'xls'], 
        accept_multiple_files=True
    )

    if uploaded_files:
        for uploaded_file in uploaded_files:
            df = process_uploaded_file(uploaded_file)
            if df is not None:
                translated_df = translate_and_combine(df)
                if translated_df is not None:
                    st.subheader(f"ç¿»è­¯çµæœï¼š{uploaded_file.name}")
                    st.dataframe(translated_df, use_container_width=True, hide_index=True)

                    # æä¾›ä¸‹è¼‰æŒ‰éˆ•
                    csv_export = translated_df.to_csv(index=False).encode('utf-8')
                    st.download_button(
                        label=f"ğŸ“¥ ä¸‹è¼‰ç¿»è­¯çµæœ ({uploaded_file.name})",
                        data=csv_export,
                        file_name=f"{uploaded_file.name}_Translated.csv",
                        mime='text/csv'
                    )

if __name__ == "__main__":
    main()
