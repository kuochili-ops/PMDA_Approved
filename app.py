import streamlit as st
import pandas as pd
import requests
import io
import re

# å¾ Streamlit Cloud Secrets Manager è®€å–é‡‘é‘°
AZURE_KEY = st.secrets["AZURE_KEY"]
AZURE_REGION = st.secrets["AZURE_REGION"]

endpoint = "https://api.cognitive.microsofttranslator.com/translate"
params = {"api-version": "3.0", "from": "ja", "to": ["zh-Hant", "en"]}
headers = {
    "Ocp-Apim-Subscription-Key": AZURE_KEY,
    "Ocp-Apim-Subscription-Region": AZURE_REGION,
    "Content-type": "application/json"
}
def translate_drug_info_ms(japanese_data_list):
    results = []
    for item in japanese_data_list:
        body = [{"text": f"{item['trade_name_jp']} {item['ingredient_jp']} {item['efficacy_jp']}"}]
        response = requests.post(endpoint, params=params, headers=headers, json=body)
        data = response.json()[0]["translations"]

        results.append({
            "trade_name_zh": data[0]["text"],
            "trade_name_en": data[1]["text"],
            "ingredient_zh": data[0]["text"],
            "ingredient_en": data[1]["text"],
            "efficacy_zh": data[0]["text"],
            "efficacy_en": data[1]["text"]
        })
    return results
def process_uploaded_file(uploaded_file):
    try:
        filename = uploaded_file.name
        file_type = uploaded_file.type
        filename_lower = filename.lower()

        if 'excel' in file_type or filename_lower.endswith(('.xlsx', '.xls')):
            df = pd.read_excel(uploaded_file, sheet_name=0, skiprows=2)
        elif 'csv' in file_type or filename_lower.endswith('.csv'):
            csv_data = io.StringIO(uploaded_file.getvalue().decode("utf-8"))
            df = pd.read_csv(csv_data, skiprows=2)
        else:
            st.error("ä¸æ”¯æ´çš„æª”æ¡ˆæ ¼å¼ã€‚")
            return None

        # æ¸…ç†æ¬„ä½åç¨±
        df.columns = df.columns.str.replace(r'[\s\nã€€]', '', regex=True)

        # æ­£å‰‡åŒ–æ¬„ä½å°æ‡‰
        rename_map = {}
        for col in df.columns:
            if re.match(r'^è²©.*å£².*å.*', col):
                rename_map[col] = 'Trade_Name_JP'
            elif re.match(r'^æˆ.*åˆ†.*å.*', col):
                rename_map[col] = 'Ingredient_JP'
            elif re.match(r'^åŠ¹èƒ½.*åŠ¹æœ.*', col):
                rename_map[col] = 'Efficacy_JP'
            elif col == 'æ‰¿èªæ—¥':
                rename_map[col] = 'Approval_Date'
            elif col == 'åˆ†é‡':
                rename_map[col] = 'Category'
            elif col.startswith('No'):
                rename_map[col] = 'No'
            elif col.startswith('æ‰¿èª'):
                rename_map[col] = 'Approval_Type'

        df = df.rename(columns=rename_map)
        key_cols = ['Category', 'Approval_Date', 'No', 'Trade_Name_JP', 'Approval_Type', 'Ingredient_JP', 'Efficacy_JP']
        df = df[key_cols].dropna(subset=['Trade_Name_JP', 'Ingredient_JP', 'Efficacy_JP'], how='all').reset_index(drop=True)

        return df
    except Exception as e:
        st.error(f"è™•ç†æª”æ¡ˆ {uploaded_file.name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None
def translate_and_combine(df):
    data_for_translation = df.apply(
        lambda row: {
            'trade_name_jp': row['Trade_Name_JP'],
            'ingredient_jp': row['Ingredient_JP'],
            'efficacy_jp': row['Efficacy_JP']
        },
        axis=1
    ).tolist()

    st.info(f"æ­£åœ¨ç¿»è­¯ {len(data_for_translation)} ç­†è—¥å“è³‡æ–™...")
    translated_results = translate_drug_info_ms(data_for_translation)

    df_translated = pd.DataFrame(translated_results)
    final_df = pd.concat([df.reset_index(drop=True), df_translated.reset_index(drop=True)], axis=1)

    display_names = {
        'Category': 'åˆ†é‡ (Category)',
        'Approval_Date': 'æ‰¿èªæ—¥',
        'No': 'No.',
        'Trade_Name_JP': 'è²©è³£å/å…¬å¸ (æ—¥æ–‡)',
        'trade_name_zh': 'å•†å“åç¨±/å…¬å¸ (ä¸­æ–‡)',
        'trade_name_en': 'Trade Name/Company (English)',
        'Ingredient_JP': 'æˆåˆ†å (æ—¥æ–‡)',
        'ingredient_zh': 'æˆåˆ†åç¨± (ä¸­æ–‡)',
        'ingredient_en': 'Ingredient Name (English)',
        'Approval_Type': 'æ‰¿èªé¡å‹',
        'Efficacy_JP': 'åŠŸæ•ˆãƒ»æ•ˆæœ (æ—¥æ–‡)',
        'efficacy_zh': 'åŠŸæ•ˆãƒ»æ•ˆæœ (ä¸­æ–‡)',
        'efficacy_en': 'Efficacy/Effects (English)'
    }
    final_df = final_df.rename(columns=display_names)
    return final_df
def main():
    st.set_page_config(layout="wide", page_title="PMDA æ—¥æœ¬æ–°è—¥ç¿»è­¯åˆ—è¡¨ç”Ÿæˆå™¨")
    st.title("ğŸ‡¯ğŸ‡µ PMDA æ—¥æœ¬æ–°è—¥ç¿»è­¯åˆ—è¡¨ç”Ÿæˆå™¨ (Microsoft Translator ç‰ˆ)")

    uploaded_files = st.file_uploader(
        "ä¸Šå‚³æ–°è—¥åˆ—è¡¨æª”æ¡ˆ (CSV/XLSX)", 
        type=['csv', 'xlsx', 'xls'], 
        accept_multiple_files=True
    )

    if uploaded_files:
        for uploaded_file in uploaded_files:
            df = process_uploaded_file(uploaded_file)
            if df is not None:
                translated_df = translate_and_combine(df)
                if translated_df is not None:
                    st.subheader(f"ç¿»è­¯çµæœï¼š{uploaded_file.name}")

                    # ğŸ”‘ åˆ†æ®µä¾æœˆä»½é¡¯ç¤º
                    translated_df["æœˆä»½"] = pd.to_datetime(translated_df["æ‰¿èªæ—¥"], errors="coerce").dt.month.astype(str) + "æœˆ"

                    month_groups = translated_df.groupby("æœˆä»½")
                    tabs = st.tabs([f"{month}" for month in month_groups.groups.keys()])

                    for i, (month, group_df) in enumerate(month_groups):
                        with tabs[i]:
                            st.header(f"{month} ç¿»è­¯çµæœ")
                            st.dataframe(group_df, use_container_width=True, hide_index=True)

                            # æä¾›ä¸‹è¼‰æŒ‰éˆ•
                            csv_export = group_df.to_csv(index=False).encode('utf-8')
                            st.download_button(
                                label=f"ğŸ“¥ ä¸‹è¼‰ {month} ç¿»è­¯çµæœ (CSV)",
                                data=csv_export,
                                file_name=f"{uploaded_file.name}_{month}_Translated.csv",
                                mime='text/csv'
                            )

if __name__ == "__main__":
    main()
