
import streamlit as st
import pandas as pd
import io
from rapidfuzz import process

st.set_page_config(page_title="æ—¥å°æ–°è—¥ä¸»æˆåˆ†æ¯”å°", layout="wide")
st.title("æ—¥æœ¬æ–°è—¥èˆ‡å°ç£æœªè¨»éŠ·è—¥å“ä¸»æˆåˆ†æ¯”å°å·¥å…·")

jp_file = st.file_uploader("è«‹ä¸Šå‚³æ—¥æœ¬ä¸Šå¸‚æ–°è—¥ä¸€è¦½è¡¨ï¼ˆExcelï¼‰", type=["xlsx"])
similarity_threshold = st.slider("è¨­å®šæ¨¡ç³Šæ¯”å°ç›¸ä¼¼åº¦é–€æª»", 50, 100, 80)

# ç¿»è­¯å­—å…¸
category_dict = {
    "æŠ—æ‚ª": "æŠ—ç™Œè—¥",
    "ãƒ¯ã‚¯ãƒãƒ³": "ç–«è‹—",
    "è¡€æ¶²": "è¡€æ¶²è£½åŠ‘",
    "ãƒã‚¤ã‚ª": "ç”Ÿç‰©è£½åŠ‘",
    "æ”¾å°„": "æ”¾å°„æ€§è—¥å“",
    "ä¸€èˆ¬": "ä¸€èˆ¬è—¥å“",
    "å¸Œå°‘ç–¾ç—…ç”¨åŒ»è–¬å“": "ç½•è¦‹ç–¾ç—…ç”¨è—¥"
}
approval_dict = {
    "æ‰¿èª": "æ–°è—¥æ ¸å‡†",
    "ä¸€å¤‰": "éƒ¨åˆ†è®Šæ›´æ ¸å‡†"
}
company_dict = {
    "ã‚ã™ã‹è£½è–¬ãˆ±": "Aska Pharmaceutical",
    "ãƒãƒãƒ«ãƒ†ã‚£ã‚¹ãƒ•ã‚¡ãƒ¼ãƒãˆ±": "Novartis Pharma",
}
ingredient_dict = {
    "ãƒ‰ãƒ­ã‚¹ãƒ”ãƒ¬ãƒãƒ³": "Drospirenone",
    "ã‚¤ãƒ—ã‚¿ã‚³ãƒ‘ãƒ³å¡©é…¸å¡©æ°´å’Œç‰©": "Iptacopan Hydrochloride Hydrate",
}
indication_dict = {
    "é¿å¦Šã‚’åŠ¹èƒ½ãƒ»åŠ¹æœã¨ã™ã‚‹æ–°åŠ¹èƒ½ãƒ»æ–°ç”¨é‡ãƒ»ãã®ä»–ã®åŒ»è–¬å“": "é¿å­•",
    "C3è…ç—‡ã‚’åŠ¹èƒ½ãƒ»åŠ¹æœã¨ã™ã‚‹æ–°åŠ¹èƒ½åŒ»è–¬å“": "C3è…ç—‡æ²»ç™‚",
}

def detect_header_row(df):
    """è‡ªå‹•åµæ¸¬æ¨™é¡Œåˆ—ä½ç½®"""
    for i in range(min(10, len(df))):  # æª¢æŸ¥å‰10åˆ—
        if "åˆ†é‡" in df.iloc[i].values or "æ‰¿èªæ—¥" in df.iloc[i].values:
            return i
    return 0  # é è¨­ç¬¬ä¸€åˆ—

def parse_japan_excel(file):
    xls = pd.ExcelFile(file)
    all_rows = []
    for sheet in xls.sheet_names:
        raw_df = pd.read_excel(xls, sheet, header=None)
        header_row = detect_header_row(raw_df)
        df = pd.read_excel(xls, sheet, header=header_row)
        
        # é¡¯ç¤ºé™¤éŒ¯è¨Šæ¯
        st.write(f"ğŸ“„ åˆ†é ï¼š{sheet}ï¼Œåµæ¸¬æ¨™é¡Œåˆ—ï¼š{header_row}ï¼Œæ¬„ä½ï¼š{df.columns.tolist()}")
        
        # æ¬„ä½å°æ‡‰å®¹éŒ¯
        col_map = {
            next((c for c in df.columns if "åˆ†é‡" in str(c)), None): "è—¥å“é¡åˆ¥",
            next((c for c in df.columns if "æ‰¿èªæ—¥" in str(c)), None): "æ ¸å‡†æ—¥",
            next((c for c in df.columns if "è²©" in str(c)), None): "å•†å“åèˆ‡è—¥å•†",
            next((c for c in df.columns if "æ‰¿èª" == str(c)), None): "æ ¸å¯ç‹€æ…‹",
            next((c for c in df.columns if "æˆ" in str(c)), None): "ä¸»æˆåˆ†",
            next((c for c in df.columns if "åŠ¹èƒ½" in str(c)), None): "ç”¨é€”"
        }
        col_map = {k: v for k, v in col_map.items() if k is not None}
        df = df.rename(columns=col_map)
        
        # æ¸…ç†ç©ºç™½åˆ—
        df = df.dropna(how='all')
        
        for _, row in df.iterrows():
            prod_info = str(row.get("å•†å“åèˆ‡è—¥å•†", ""))
            ingr_jp = str(row.get("ä¸»æˆåˆ†", "")).strip()
            if not prod_info or not ingr_jp:
                continue
            if "ï¼ˆ" in prod_info:
                prod_name = prod_info.split("ï¼ˆ")[0].strip()
                company_jp = prod_info.split("ï¼ˆ")[-1].replace("ï¼‰", "").strip()
            else:
                prod_name = prod_info
                company_jp = ""
            ingr_en = ingredient_dict.get(ingr_jp, ingr_jp)
            company_en = company_dict.get(company_jp, company_jp)
            indication_jp = str(row.get("ç”¨é€”", "")).strip()
            indication_zh = indication_dict.get(indication_jp, indication_jp)
            category_zh = category_dict.get(row.get("è—¥å“é¡åˆ¥", ""), row.get("è—¥å“é¡åˆ¥", ""))
            approval_zh = approval_dict.get(row.get("æ ¸å¯ç‹€æ…‹", ""), row.get("æ ¸å¯ç‹€æ…‹", ""))
            all_rows.append({
                "æœˆä»½": sheet,
                "è—¥å“é¡åˆ¥": category_zh,
                "æ ¸å‡†æ—¥": row.get("æ ¸å‡†æ—¥", ""),
                "å•†å“å": prod_name,
                "è—¥å•†": company_en,
                "ä¸»æˆåˆ†": ingr_en,
                "ç”¨é€”": indication_zh,
                "æ ¸å¯ç‹€æ…‹": approval_zh,
            })
    return pd.DataFrame(all_rows)

if jp_file:
    with st.spinner("è³‡æ–™è™•ç†ä¸­ï¼Œè«‹ç¨å€™..."):
        jp_df = parse_japan_excel(jp_file)
        if jp_df.empty:
            st.error("âš  æœªè®€å–åˆ°ä»»ä½•æ—¥æœ¬æ–°è—¥è³‡æ–™ï¼Œè«‹æª¢æŸ¥ Excel æ ¼å¼ã€‚")
        else:
            tw_df = pd.read_csv("37_2.csv")
            st.subheader("æ—¥æœ¬æ–°è—¥é …ç›®è³‡è¨Š")
            st.dataframe(jp_df)

            st.subheader("ä¸»æˆåˆ†æ¯”å°å°ç£æœªè¨»éŠ·è—¥å“çµæœï¼ˆå«æ¨¡ç³Šæ¯”å°ï¼‰")
            results = []
            tw_ingredients = tw_df["ä¸»æˆåˆ†"].astype(str).str.strip().tolist()

            for _, row in jp_df.iterrows():
                jp_inn = str(row["ä¸»æˆåˆ†"]).strip()
                match, score, _ = process.extractOne(jp_inn, tw_ingredients)
                if score >= similarity_threshold:
                    matched = tw_df[tw_df["ä¸»æˆåˆ†"].astype(str).str.strip() == match]
                    for _, tw_row in matched.iterrows():
                        results.append({
                            "æ—¥æœ¬ä¸»æˆåˆ†": jp_inn,
                            "æ—¥æœ¬å•†å“å": row["å•†å“å"],
                            "æ—¥æœ¬æ ¸å‡†æ—¥": row["æ ¸å‡†æ—¥"],
                            "æ—¥æœ¬ç”¨é€”": row["ç”¨é€”"],
                            "æ—¥æœ¬è—¥å•†": row["è—¥å•†"],
                            "æ—¥æœ¬æ ¸å¯ç‹€æ…‹": row["æ ¸å¯ç‹€æ…‹"],
                            "å°ç£å•†å“å": tw_row.get("å•†å“å", ""),
                            "å°ç£ä¸»æˆåˆ†": tw_row.get("ä¸»æˆåˆ†", ""),
                            "å°ç£åŠ‘å‹/è¦æ ¼": tw_row.get("åŠ‘å‹/è¦æ ¼", ""),
                            "å°ç£è—¥å•†": tw_row.get("è—¥å•†", ""),
                            "å°ç£è¨±å¯è­‰è™Ÿ": tw_row.get("è¨±å¯è­‰è™Ÿ", ""),
                            "æ¯”å°ç›¸ä¼¼åº¦": score
                        })
                else:
                    results.append({
                        "æ—¥æœ¬ä¸»æˆåˆ†": jp_inn,
                        "æ—¥æœ¬å•†å“å": row["å•†å“å"],
                        "æ—¥æœ¬æ ¸å‡†æ—¥": row["æ ¸å‡†æ—¥"],
                        "æ—¥æœ¬ç”¨é€”": row["ç”¨é€”"],
                        "æ—¥æœ¬è—¥å•†": row["è—¥å•†"],
                        "æ—¥æœ¬æ ¸å¯ç‹€æ…‹": row["æ ¸å¯ç‹€æ…‹"],
                        "å°ç£å•†å“å": "ç„¡ä¸Šå¸‚å“é …",
                        "å°ç£ä¸»æˆåˆ†": "",
                        "å°ç£åŠ‘å‹/è¦æ ¼": "",
                        "å°ç£è—¥å•†": "",
                        "å°ç£è¨±å¯è­‰è™Ÿ": "",
                        "æ¯”å°ç›¸ä¼¼åº¦": score
                    })

            result_df = pd.DataFrame(results)
            st.dataframe(result_df)

            # CSV ä¸‹è¼‰
            csv = result_df.to_csv(index=False).encode('utf-8-sig')
            st.download_button("ä¸‹è¼‰æ¯”å°çµæœ (CSV)", csv, "compare_result.csv", "text/csv")

            # Excel ä¸‹è¼‰
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                result_df.to_excel(writer, index=False, sheet_name='æ¯”å°çµæœ')
            st.download_button("ä¸‹è¼‰æ¯”å°çµæœ (Excel)", output.getvalue(), "compare_result.xlsx", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
else:
    st.info("è«‹ä¸Šå‚³æ—¥æœ¬æ–°è—¥ Excel æª”æ¡ˆã€‚")

st.markdown("---")
st.markdown("æœ¬å·¥å…·åƒ…ä¾›å­¸è¡“æˆ–å…§éƒ¨åƒè€ƒï¼Œè³‡æ–™ä¾†æºè«‹è‡ªè¡Œç¢ºèªã€‚")
